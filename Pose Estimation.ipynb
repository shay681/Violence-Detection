{"cells":[{"cell_type":"markdown","metadata":{"id":"AUw0J5JOltDH"},"source":["# Pose Estimation"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3336,"status":"ok","timestamp":1672044281115,"user":{"displayName":"Shay Doner","userId":"16301994504083794988"},"user_tz":-120},"id":"GG2-4lxImbqA","outputId":"7500da03-95b0-46c6-c7fe-e7c6138cd006"},"outputs":[],"source":["!git clone https://www.github.com/WongKinYiu/yolov7.git"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":656,"status":"ok","timestamp":1672044302698,"user":{"displayName":"Shay Doner","userId":"16301994504083794988"},"user_tz":-120},"id":"c7cZr1owltDQ"},"outputs":[],"source":["import cv2\n","import numpy as np\n","import os\n","import sys\n","import tqdm\n","import h5py\n","import gc"]},{"cell_type":"markdown","metadata":{"id":"5NWamkJkltDU"},"source":["## utils_preprocess"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4243,"status":"ok","timestamp":1672044314302,"user":{"displayName":"Shay Doner","userId":"16301994504083794988"},"user_tz":-120},"id":"LCAMMvw5ltDX"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","from os import listdir\n","from os.path import isfile, join\n","import cv2 as cv\n","import torch\n","from torchvision import transforms\n","import sys\n","\n","sys.path.insert(1, 'yolov7/') \n","\n","from utils.datasets import letterbox\n","from utils.general import non_max_suppression_kpt\n","from utils.plots import output_to_keypoint, plot_skeleton_kpts"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":339,"status":"ok","timestamp":1672044321666,"user":{"displayName":"Shay Doner","userId":"16301994504083794988"},"user_tz":-120},"id":"piwqGITmltDZ"},"outputs":[],"source":["def get_file_names_from_dir(dir: str):\n","    return [dir + f for f in listdir(dir) if isfile(join(dir, f))]\n","\n","\n","def read_video_from_file(file: str):\n","    return cv.VideoCapture(file)\n","\n","\n","def play_video(video):\n","    video_window = 'video_window'\n","    cv.namedWindow(video_window)\n","    while True:\n","        ret, frame = video.read()  # read a single frame\n","        if not ret:\n","            print(\"EOV or Could not read the frame\")\n","            cv.destroyWindow(video_window)\n","            break\n","        reescaled_frame = frame\n","        #     for i in range(scaleLevel-1):\n","        #         reescaled_frame = cv.pyrDown(reescaled_frame)\n","        cv.imshow(video_window, reescaled_frame)\n","        waitKey = (cv.waitKey(1) & 0xFF)\n","        if waitKey == ord('q'):  # if Q pressed you could do something else with other keypress\n","            cv.destroyWindow(video_window)\n","            video.release()\n","            break\n","\n","\n","def break_video_into_frames(video, p=False):\n","    frames = []\n","    success = True\n","    while success:\n","        success, frame = video.read()\n","        frames.append(frame)\n","    if (p):\n","        print(f'Readed {len(frames)} frames.')\n","    return frames\n","\n","\n","def display_frame(frame):\n","    cv.imshow('Frame:', frame)\n","    cv.waitKey(0)\n","    cv.destroyAllWindows()\n","\n","\n","def play_frames(frames):\n","    video_window = 'video_window'\n","    cv.namedWindow(video_window)\n","    for f in frames:\n","        cv.imshow(video_window, f)\n","        waitKey = (cv.waitKey(1) & 0xFF)\n","        if waitKey == ord('q'):  # if Q pressed you could do something else with other keypress\n","            cv.destroyWindow(video_window)\n","            break\n","\n","\n","def loop_frames(frames):\n","    video_window = 'video_window'\n","    cv.namedWindow(video_window)\n","    last_frame_index = len(frames) - 1\n","    i = 0\n","    while i != last_frame_index:\n","        if (i + 1) == last_frame_index:\n","            i = 0\n","        cv.imshow(video_window, frames[i])\n","        i = i + 1\n","        waitKey = (cv.waitKey(1) & 0xFF)\n","        if waitKey == ord('q'):  # if Q pressed you could do something else with other keypress\n","            cv.destroyWindow(video_window)\n","            break\n","\n","\n","def load_model(model_path):\n","    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","    model = torch.load(model_path, map_location=device)['model']\n","    # Put in inference mode\n","    model.float().eval()\n","\n","    if torch.cuda.is_available():\n","        print('using gpu')\n","        # half() turns predictions into float16 tensors\n","        # which significantly lowers inference time\n","        model.half().to(device)\n","    return model\n","\n","\n","def run_inference(frame, model):\n","    # Resize and pad image\n","    frame_letter = letterbox(frame, 960, stride=64, auto=True)[0] # shape: (768, 960, 3)\n","    # Apply transforms\n","    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","    frame_letter = transforms.ToTensor()(frame_letter).half().to(device) # torch.Size([3, 768, 960])\n","    # Turn image into batch\n","    frame_unsqueeze = frame_letter.unsqueeze(0) # torch.Size([1, 3, 768, 960])\n","    with torch.no_grad():\n","        output, _ = model(frame_unsqueeze) # torch.Size([1, 45900, 57])\n","    del frame, frame_letter\n","    del model\n","    return output, frame_unsqueeze\n","\n","\n","def visualize_output(output, image, save_path, model, show = False):\n","    plt.clf()\n","    nimg = image[0].permute(1, 2, 0) * 255\n","    nimg = nimg.cpu().numpy().astype(np.uint8)\n","    nimg = cv.cvtColor(nimg, cv.COLOR_RGB2BGR)\n","    print(f'the output shape is: {output.shape}')\n","    for idx in range(output.shape[0]):\n","        plot_skeleton_kpts(nimg, output[idx, 7:].T, 3)\n","    plt.figure(figsize=(12, 12))\n","    plt.axis('off')\n","    plt.imshow(nimg)\n","    plt.savefig(save_path)\n","    if show:\n","        plt.show()\n","\n","    \n","\n","#supress keypoints below the confidence threshold \n","def supress_kpt(unfiltered_output, model):\n","    output = non_max_suppression_kpt(unfiltered_output, \n","                0.25, # Confidence Threshold\n","                0.65, # IoU Threshold\n","                nc=model.yaml['nc'], # Number of Classes\n","                nkpt=model.yaml['nkpt'], # Number of Keypoints\n","                kpt_label=True)\n","    return output"]},{"cell_type":"markdown","metadata":{"id":"y_U0WtdeltDe"},"source":["## main"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":76227,"status":"ok","timestamp":1672047563505,"user":{"displayName":"Shay Doner","userId":"16301994504083794988"},"user_tz":-120},"id":"NkAb6BKhltDg","outputId":"1559f01e-4d1e-488f-cfb9-402b9f946de5"},"outputs":[],"source":["VIOLENT_PATH = 'data/train/Fight/'\n","NON_VIOLENT_PATH = 'data/train/NonFight'\n","IMAGES_OUT_FOLDER = 'poses_visualsition/'\n","H5_OUT_PATH = 'data/poses_pickle.h5'\n","POSE_ESTIMATION_MODEL_PATH = 'yolov7/yolov7-w6-pose.pt'\n","\n","if __name__ == \"__main__\":\n","    with h5py.File(H5_OUT_PATH, 'w') as hf:\n","        violent_videos_files = get_file_names_from_dir(VIOLENT_PATH)\n","        non_violent_videos_files = get_file_names_from_dir(NON_VIOLENT_PATH)\n","        classes_paths = {'violent': VIOLENT_PATH, 'non_viloent': NON_VIOLENT_PATH}\n","\n","        video = read_video_from_file(violent_videos_files[-1])\n","        video_frames = break_video_into_frames(video, True)\n","        # loop_frames(video_frames)\n","\n","        # create dictionary with the output pose embeddings\n","        \n","        pose_estimation_model = load_model(POSE_ESTIMATION_MODEL_PATH)\n","\n","        # Folder names are used as pose class names.\n","        for class_name, class_path in classes_paths.items():\n","            if not os.path.exists(os.path.join(IMAGES_OUT_FOLDER, class_name)):\n","                os.makedirs(os.path.join(IMAGES_OUT_FOLDER, class_name))\n","            \n","            class_videos_files = get_file_names_from_dir(class_path)\n","            images_out_folder_class = os.path.join(IMAGES_OUT_FOLDER, class_name)\n","            for video_file in tqdm.tqdm(class_videos_files, position=0):\n","                video = read_video_from_file(video_file)\n","                video_frames = break_video_into_frames(video, True)\n","                \n","                video_name = os.path.basename(video_file)\n","                video_name = os.path.splitext(video_name)[0]\n","                frame_num = 0\n","                for frame in video_frames:\n","                    if frame is not None:\n","                        # create a unique name for current frame\n","                        image_name = f'{video_name}_{frame_num}.png'\n","                        # print(image_name)\n","                        visualize_plot_path = os.path.join(images_out_folder_class, image_name)\n","\n","                        # run pose estimation on frame\n","                        output, image =  run_inference(frame,pose_estimation_model) \n","                        # output =  run_inference(frame,pose_estimation_model) \n","                        # filter keypoints with low score\n","                        supressed_output = supress_kpt(output, pose_estimation_model)\n","                        with torch.no_grad():\n","                            keypoints = output_to_keypoint(supressed_output)\n","                        # print(type(keypoints))\n","                        \n","                        # plot the pose estimation on top of the frame\n","                        visualize_output(keypoints, image, visualize_plot_path, pose_estimation_model, show = False)\n","                        # del output, image\n","                        torch.cuda.empty_cache()\n","                        gc.collect()\n","\n","\n","                        # add output to dataframe\n","                        hf.create_dataset(f\"{class_name}/{video_name}/{frame_num}\",  data= keypoints)\n","                        \n","                        frame_num = frame_num + 1"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"2a0e92e69bdb2ed0d947361424263fc828fa5c075b2d465730d0fd88045b73eb"}}},"nbformat":4,"nbformat_minor":0}
